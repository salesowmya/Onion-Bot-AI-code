# -*- coding: utf-8 -*-
"""ONIONBOT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jnNv1xrd3Go17MWVrBj-pBBT_mCJVD7n
"""

import pandas as pd

# Create a DataFrame from the provided data
data = {
    'Weight (KG)': [
        0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,
        1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9,
        2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9,
        3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,
        4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9,
        5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9,
        6, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9,
        7, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9,
        8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9,
        9, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9,
        10
    ],
    'Yeild in 1 acre(quinntals)': [
        0, 100.5, 101, 101.5, 102, 102.5, 103, 103.5, 104, 104.5,
        105, 105.5, 106, 106.5, 107, 107.5, 108, 108.5, 109, 109.5,
        110, 110.5, 111, 111.5, 112, 112.5, 113, 113.5, 114, 114.5,
        115, 115.5, 116, 116.5, 117, 117.5, 118, 118.5, 119, 119.5,
        120, 120.5, 121, 121.5, 122, 122.5, 123, 123.5, 124, 124.5,
        125, 125.5, 126, 126.5, 127, 127.5, 128, 128.5, 129, 129.5,
        130, 130.5, 131, 131.5, 132, 132.5, 133, 133.5, 134, 134.5,
        135, 135.5, 136, 136.5, 137, 137.5, 138, 138.5, 139, 139.5,
        140, 140.5, 141, 141.5, 142, 142.5, 143, 143.5, 144, 144.5,
        145, 145.5, 146, 146.5, 147, 147.5, 148, 148.5, 149, 149.5,
        150
    ]
}

df = pd.DataFrame(data)

# Save the DataFrame to an h5 file
df.to_hdf('data.h5', key='data', mode='w')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/onionweight.csv', encoding='latin1')

df.head()

sns.pairplot(df)

sns.heatmap(df.corr())

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder
l=LabelEncoder()
for i in df.columns:
  if df[i].dtype=='object':
    df[i]=l.fit_transform(df[i])

X = df.iloc[:, 0:1].values  # Selecting the first column as features
y = df.iloc[:, 1].values  # Selecting the second column as target

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(X_train,y_train)

from sklearn.metrics import mean_squared_error,r2_score
y_pred = rf.predict(X_test)

print(y_pred)

print("Training Accuracy :", rf.score(X_train,y_train))
print("Testing Accuracy :", rf.score(X_test,y_test))

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor()
dt.fit(X_train,y_train)
y_pred = dt.predict(X_test)

print(y_pred)

print("Training Accuracy :", dt.score(X_train,y_train))
print("Testing Accuracy :", dt.score(X_test,y_test))

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train,y_train)
y_pred = lr.predict(X_test)
print(y_pred)

print("Training Accuracy :", lr.score(X_train,y_train))
print("Testing Accuracy :", lr.score(X_test,y_test))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Assuming X_train, X_test, y_train, and y_test are defined
train_sizes = np.linspace(0.1, 0.9, 10)  # Varying training data sizes

train_accuracy = []
test_accuracy = []

for size in train_sizes:
    # Splitting the data
    X_train_subset, _, y_train_subset, _ = train_test_split(X_train, y_train, train_size=size, random_state=42)

    # Creating and fitting the model
    rf = RandomForestRegressor()
    rf.fit(X_train_subset, y_train_subset)

    # Calculating accuracies
    train_accuracy.append(rf.score(X_train_subset, y_train_subset))
    test_accuracy.append(rf.score(X_test, y_test))

# Plotting the graph
plt.plot(train_sizes, train_accuracy, label='Training Accuracy')
plt.plot(train_sizes, test_accuracy, label='Testing Accuracy')
plt.xlabel('Training Data Size')
plt.ylabel('Accuracy')
plt.title('Accuracy vs. Training Data Size for RandomForestRegressor')
plt.legend()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define a simple model
model = Sequential()
model.add(Dense(10, input_dim=1, activation='relu'))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(loss='mse', optimizer='adam')

# Train the model (example data)
X = [[1], [2], [3]]
y = [1, 2, 3]
model.fit(X, y, epochs=10)

# Save the model
model.save('model.h5')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder
l=LabelEncoder()
for i in df.columns:
  if df[i].dtype=='object':
    df[i]=l.fit_transform(df[i])

X = df.iloc[:, 0:1].values  # Selecting the first column as features
y = df.iloc[:, 1].values  # Selecting the second column as target

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np

# Define a simple regression model
model = Sequential()
model.add(Dense(10, input_dim=1, activation='relu'))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(loss='mse', optimizer='adam')

# Generate example data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 6, 8, 10])

# Train the model
model.fit(X, y, epochs=100, verbose=0)

# Save the model
model.save('regression_model.h5')